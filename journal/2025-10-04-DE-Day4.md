# Journal ‚Äî 10-04-2025 ‚Äî Data Quality & Review of DE Workflow

## 1) What I learned (bullets, not prose)
- [ ] checks -> monitoring -> modelling
- [ ] Quality -> Trust
- [ ] AI amplifies bad inputs -> bigger, faster mistakes
- [ ] Data Quality is not 1 time thing, should be implemented across the process, double check!
- [ ] AI amplifies bad inputs -> bigger, faster mistakes
- [ ] Referential integrity: every id_assessment_exists in assessments

      Where do DQ lives in the stack?
- [ ] Ingestion (raw) - schema/tu[e, volume. freshness (number of rows, columns)
- [ ] Transform (clean) - nulls, categories, FKs
- [ ] Mart - resonableness, uniqueness, business rules
- [ ] 

## 2) New vocabulary (define in your own words)
- **Quality: Accuracy** - correct, error-free, dependable
- **Quality: Completeness** - comprehensive, no missing/obsolete records
- **Quality: Reliability** - should be extracted from reliable sources; consistent, without contradictions
- **Quality: Relevancy** - relevant for the purpose which it was collected
- **Quality: Timeliness** - up-to-date and readily available

## 3) Data Engineering mindset applied (what principles did I use?)
- Creating infrastructure/systems
- There is always tradeoff/s

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- 

## 5) Open questions (things I still don‚Äôt get)
- ‚ùì kapag ba sa star schema, sa clean pa lang ay tatanggalin na yung mga unnecessary columns? or sa paglagay lang ng dims/facts table tiyaka magaalis?


## 6) Next actions (small, doable steps)
- [ ] Learn simple to advanced SQL Queries.  
- [ ] Learn basic Python (Enroll in Tutorials Dojo).
- [ ] Use tracker for the group activities.


## 7) Artifacts & links (code, queries, dashboards)
- 

---

### Mini reflection (3‚Äì5 sentences)
Consult. Collaborate. Innovate. Robust. Well-documented.

Something that will persist in long time.


### üòÇ BONUS: Meme of the day  

![Alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS6iIRtNXeyWe2fCBZlZX7zd8nQNhc0l5FTtA&s "huhu")


