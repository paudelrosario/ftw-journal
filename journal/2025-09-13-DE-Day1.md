# Journal — 9-13-2025


## 1) What I learned (bullets, not prose)
- I learned how to write a learning journal
- Clickhouse is a high performance, column-oriented SQL, analytical processing platform, storage of data
- unstructured data (e.g. images, documents, e-mail)
- semi-structured data (e.g. json structure format, web structure)
- Row-oriented DB 
    - stores/retrieves data by row - may read unnessary columns
    - fast for insert/updates (OLTP)
- Column-oriented DP 
    - stores/receives data by column; reads only needed columns
    - slower writes, optimized for reads (OLAP)
    - aggregations are efficients
    - high compression due to similar column values

- SQL Commands
    1. DDL (Design) - CREATE; DROP; ALTER; TRUNCATE
    2. DML (Manipulation) - INSERT; UPDATE; DELETE (mostly used in OLTP)
    3. TCL (Transaction) - COMMIT; SAVEPOINT; ROLLBACK
    4. DQL (Query) - Select
    5. DCL (Control) - GRANT; Revoke

- ACTIVITY 1:
SELECT name, mpg, horsepower
FROM raw.autompg___cars ac
WHERE cylinders = '8'
ORDER BY mpg DESC;

"What are the names, miles per gallon (mpg), and horsepower of all cars with 8 cylinders, ordered from most to least fuel efficient?".

Query Focus:
It selects only those cars that have 8 cylinders.
For these cars, it retrieves their name, mpg, and horsepower attributes.
The results are then sorted so that cars with the highest mpg (fuel efficiency) are listed first.

- DataTypes Matter
COMMON DATA TYPES
    - Numeric: Int; Decimal(8); Float(16); Numeric
    - String: Char; Varchar; Text
    - Data/Time: Data; Time; DateTime
    - Binary: Binary; blob
    - Boolean: Boolean
    - Special: UUID; AON, XML, JSON

- Why Data Cleaning Matters?
    - poor quality data -> bad decision
    - accuracy, reliability, trust
    - DE Mindset: Cleaning & Standardization happens in stages

    GETTING THE DATA "RIGHT"
        - Completeness
        - Accuracy
        - Consistency
        - Validity
        - Uniqueness
        - Integrity

<img src="https://www.netsuite.com/portal/assets/img/business-articles/data-warehouse/infographic-big-data.jpg?v2" alt="Infographic showing the 6Vs of Big Data: Volume, Variety, Velocity, Veracity, Value, and Variability." width="300">


## 2) New vocabulary (define in your own words)
- **term** — my definition
- SQL - Structured Query language (https://www.w3schools.com/sql/sql_intro.asp)
- DBMS - SQL Database Management System
- OLAP - Online Analytical  Processing (analytical, denormalised, historical data, shows queries, stores the record above db for analysis purpose)
- OLTP - Online Transactional Processing (designed for operational functions, branch-level db ex. live day-to-day operation, productions)
- Impute - replacement of new value


## 3) Data Engineering mindset applied (what principles did I use?)
- Keeling files and folders neat by using clear names, so I can find things easily.

## 4) Decisions & assumptions (why, alternatives, trade-offs)
None so far...

## 5) Open questions (things I still don’t get)
- Advanced SQL queries... but I'm eager to learn more about it. 


## 6) Next actions (small, doable steps)
- [ ] Study Git to understand version control basics, commands, and workflows.
- [ ] Study SQL to improve querying and managing databases efficiently.

## 7) Artifacts & links (code, queries, dashboards)
- Metabase
- https://psf-aai.vercel.app/careermap
- https://www.netsuite.com/portal/resource/articles/data-warehouse/big-data.shtml
---


### Mini reflection (3–5 sentences)
Understanding SQL and data types is very important for data engineering work. Learning the difference between OLTP (for transactional tasks) and OLAP (for data analysis) made things clearer. Next time, I want to practice more with data types and writing better SQL queries. In real work, I will be careful to keep data clean and use the right system for the right task.



### BONUS: What is a meme that best describes what you feel or your learning today?


![Alt text](https://i.imgflip.com/1146fq.jpg "TO BE THE BEST, YOU HAVE TO LEARN FROM THE BEST")
